{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bugrayildirim/brain-tumor-mri-classification?scriptVersionId=264003414\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Akbank Derin Öğrenme Bootcamp: Brain Tumor MRI Classification\n**Proje amacı:** CNN tabanlı model kullanarak MR görüntülerinden beyin tümörünü sınıflandırmak; model performansını değerlendirmek ve Grad-CAM ile model açıklanabilirliği sağlamak.\n\n**Veri seti:** masoudnickparvar/brain-tumor-mri-dataset (Kaggle). Dataset 4 sınıf içerir: glioma, meningioma, pituitary, no_tumor (toplam ~7k görüntü).\n\n**Geliştirme ortamı:** Kaggle Notebook (tüm hücreler ve görselleştirmeler notebook içinde yer alacaktır). Bootcamp gereksinimleri dikkate alındı.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, optimizers, callbacks\n\n# Reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n\n# Kaggle dataset root \nDATA_DIR = \"/kaggle/input/brain-tumor-mri-dataset\"\nprint(\"DATA_DIR exists:\", os.path.exists(DATA_DIR))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:11:18.974081Z","iopub.execute_input":"2025-09-25T17:11:18.974346Z","iopub.status.idle":"2025-09-25T17:11:32.788374Z","shell.execute_reply.started":"2025-09-25T17:11:18.974319Z","shell.execute_reply":"2025-09-25T17:11:32.787702Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1. Veri Ön İşleme ve Data Augmentation\n\n- Görüntüler `flow_from_directory` ile sınıf klasörlerinden okunacak.\n- Eğitim sırasında ImageDataGenerator ile dönüşümler uygulanacak: rotation, horizontal/vertical flip, zoom, brightness (color jitter etkisi).\n- Train/validation/test split: dataset klasörleri hazır bölünmemişse `validation_split` ile split yapılacaktır.\n","metadata":{}},{"cell_type":"code","source":"# Parametreler\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.05,\n    zoom_range=0.15,\n    horizontal_flip=True,\n    vertical_flip=False,\n    brightness_range=[0.8,1.2],\n    validation_split=0.2,   # train/val split\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_dir = os.path.join(DATA_DIR, \"Training\") if os.path.exists(os.path.join(DATA_DIR, \"Training\")) else DATA_DIR\n# Eğer dataset doğrudan class klasörleri içeriyorsa DATA_DIR kullan; değilse Kaggle versiyonuna göre \"Training\" veya \"train\" klasörlerini kontrol et.\nprint(\"Listing top-level:\", os.listdir(DATA_DIR)[:10])\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"training\",\n    seed=SEED\n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    color_mode=\"rgb\",\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"validation\",\n    seed=SEED\n)\n\n# Eğer ayrı test klasörü varsa onu da test_datagen ile yükleyin:\ntest_dir = os.path.join(DATA_DIR, \"Testing\")\nif os.path.exists(test_dir):\n    test_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=IMG_SIZE,\n        batch_size=BATCH_SIZE,\n        class_mode=\"categorical\",\n        shuffle=False\n    )\nelse:\n    test_generator = None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:11:32.789727Z","iopub.execute_input":"2025-09-25T17:11:32.790184Z","iopub.status.idle":"2025-09-25T17:11:34.939897Z","shell.execute_reply.started":"2025-09-25T17:11:32.790164Z","shell.execute_reply":"2025-09-25T17:11:34.939303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Model Mimarisi ve Eğitimi\n\nİki seçenek sunuyorum:\n- A) Küçük, baştan inşa edilmiş bir CNN (örnek: baseline).\n- B) Transfer Learning: Önceden eğitilmiş bir model (ör: EfficientNetB0 veya VGG16) üzerine fine-tune.\n\nAşağıda önce baseline CNN kodu veriliyor; ardından transfer learning örneği de yorum satırıyla eklenmiştir.\n","metadata":{}},{"cell_type":"code","source":"num_classes = train_generator.num_classes\nprint(\"Num classes:\", num_classes)\n\ndef build_baseline_cnn(input_shape=IMG_SIZE + (3,), num_classes=num_classes):\n    inputs = layers.Input(shape=input_shape)\n    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n    x = layers.MaxPooling2D((2,2))(x)\n    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n    x = layers.MaxPooling2D((2,2))(x)\n    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n    x = layers.MaxPooling2D((2,2))(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dropout(0.4)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    model = models.Model(inputs, outputs, name=\"baseline_cnn\")\n    return model\n\nmodel = build_baseline_cnn()\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:11:34.940673Z","iopub.execute_input":"2025-09-25T17:11:34.940917Z","iopub.status.idle":"2025-09-25T17:11:36.963837Z","shell.execute_reply.started":"2025-09-25T17:11:34.940893Z","shell.execute_reply":"2025-09-25T17:11:36.963139Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Transfer Learning ile Model Geliştirme (Opsiyonel)\n\nBurada, önceden eğitilmiş bir model (EfficientNetB0) kullanarak fine-tuning yapacağız.  \nBu yaklaşım sayesinde sınırlı veriyle daha güçlü özellik çıkarımı sağlanabilir.  \nİlk aşamada base model eğitimde **dondurulacak**, daha sonra bazı katmanlar eğitim moduna alınabilir.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nbase_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,))\nbase_model.trainable = False  # önce feature extractor olarak kullan\n\ninputs = layers.Input(shape=IMG_SIZE + (3,))\nx = base_model(inputs, training=False)\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dropout(0.3)(x)\nx = layers.Dense(128, activation='relu')(x)\noutputs = layers.Dense(num_classes, activation='softmax')(x)\ntl_model = models.Model(inputs, outputs)\n\ntl_model.compile(optimizer=optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\ntl_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:11:36.96526Z","iopub.execute_input":"2025-09-25T17:11:36.965502Z","iopub.status.idle":"2025-09-25T17:11:38.659522Z","shell.execute_reply.started":"2025-09-25T17:11:36.965484Z","shell.execute_reply":"2025-09-25T17:11:38.658787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Model Eğitimi: Callbacks & Eğitim Süreci\n\nAşağıda kullanılan callback’ler:\n- **ModelCheckpoint**: En iyi modeli kaydetme  \n- **EarlyStopping**: Aşırı öğrenmeyi önlemek için durdurma  \n- **ReduceLROnPlateau**: Validation loss iyileşmezse learning rate’i düşürme  \n\nEğitim epoch sayısı ve callback yapılandırması aşağıdadır.\n","metadata":{}},{"cell_type":"code","source":"EPOCHS = 15\n\ncheckpoint_cb = callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\nearlystopping_cb = callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\nreduce_lr_cb = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    callbacks=[checkpoint_cb, earlystopping_cb, reduce_lr_cb]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:11:38.660304Z","iopub.execute_input":"2025-09-25T17:11:38.660589Z","iopub.status.idle":"2025-09-25T17:24:12.704466Z","shell.execute_reply.started":"2025-09-25T17:11:38.660563Z","shell.execute_reply":"2025-09-25T17:24:12.703825Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Eğitim Sonuçları: Accuracy & Loss Grafikleri\n\nBu hücre ile eğitim sürecindeki doğruluk (accuracy) ve kayıp (loss) eğilimlerini görselleştireceğiz.  \nGrafikler, overfitting / underfitting durumlarını izlemede yardımcı olur.\n","metadata":{}},{"cell_type":"code","source":"# Eğitim grafikleri\ndef plot_history(h):\n    plt.figure(figsize=(12,5))\n    plt.subplot(1,2,1)\n    plt.plot(h.history['accuracy'], label='train_acc')\n    plt.plot(h.history['val_accuracy'], label='val_acc')\n    plt.title('Accuracy')\n    plt.legend()\n    plt.grid(True)\n\n    plt.subplot(1,2,2)\n    plt.plot(h.history['loss'], label='train_loss')\n    plt.plot(h.history['val_loss'], label='val_loss')\n    plt.title('Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\nplot_history(history)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:24:12.705359Z","iopub.execute_input":"2025-09-25T17:24:12.705664Z","iopub.status.idle":"2025-09-25T17:24:13.026466Z","shell.execute_reply.started":"2025-09-25T17:24:12.705644Z","shell.execute_reply":"2025-09-25T17:24:13.025744Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Model Değerlendirme: Confusion Matrix & Classification Report\n\nTest veya validation seti üzerinde modelin sınıflandırma performansını inceleyeceğiz.  \n- **Classification Report** ile precision, recall, f1-score değerlerini göreceğiz  \n- **Confusion Matrix** ile sınıflar arasındaki karışmaları görselleştireceğiz  \n","metadata":{}},{"cell_type":"code","source":"# Eğer test_generator varsa kullan; yoksa validation üzerinde değerlendirme yap\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nif test_generator is not None:\n    steps = test_generator.samples // test_generator.batch_size + 1\n    preds = model.predict(test_generator, steps=steps)\n    y_pred = np.argmax(preds, axis=1)\n    y_true = test_generator.classes\n    class_indices = test_generator.class_indices\nelse:\n    # validation generator üzerinden tahmin örneği\n    steps = validation_generator.samples // validation_generator.batch_size + 1\n    preds = model.predict(validation_generator, steps=steps)\n    y_pred = np.argmax(preds, axis=1)\n    y_true = validation_generator.classes\n    class_indices = validation_generator.class_indices\n\nlabels = list(class_indices.keys())\nprint(\"Classes:\", labels)\n\nprint(\"Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=labels))\n\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels)\nplt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:24:13.027408Z","iopub.execute_input":"2025-09-25T17:24:13.027679Z","iopub.status.idle":"2025-09-25T17:24:22.282692Z","shell.execute_reply.started":"2025-09-25T17:24:13.027661Z","shell.execute_reply":"2025-09-25T17:24:22.281993Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Grad-CAM Görselleştirmesi\n\nGrad-CAM ile modelin hangi bölgelere bakarak karar verdiğini görselleştiriyoruz. Keras örnekleri ve rehberleriyle uyumlu bir uygulama takip edilmektedir. (Keras Grad-CAM örneği). :contentReference[oaicite:7]{index=7}\n","metadata":{}},{"cell_type":"code","source":"# Grad-CAM fonksiyonu — Keras resmi örneğinden uyarlanmıştır. :contentReference[oaicite:8]{index=8}\nimport tensorflow.keras.backend as K\nimport cv2\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n\n    grads = tape.gradient(class_channel, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)\n    return heatmap.numpy()\n\n# Örnek kullanım: validation'dan bir batch al ve Grad-CAM uygula\nlast_conv_layer = None\n# otomatik bulmaya çalış\nfor layer in reversed(model.layers):\n    if isinstance(layer, layers.Conv2D):\n        last_conv_layer = layer.name\n        break\nprint(\"Last conv layer:\", last_conv_layer)\n\n# Test için tek bir görüntü al\nx_batch, y_batch = next(iter(validation_generator))\nimg = x_batch[0]\ninp = np.expand_dims(img, axis=0)\n\nheatmap = make_gradcam_heatmap(inp, model, last_conv_layer)\n# Resize heatmap to image size\nheatmap = cv2.resize(heatmap, (IMG_SIZE[1], IMG_SIZE[0]))\nheatmap = np.uint8(255 * heatmap)\nheatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\nsuperimposed_img = cv2.addWeighted(cv2.cvtColor((img*255).astype('uint8'), cv2.COLOR_RGB2BGR), 0.6, heatmap, 0.4, 0)\n# Display\nplt.figure(figsize=(8,4))\nplt.subplot(1,2,1); plt.imshow(img); plt.title('Input'); plt.axis('off')\nplt.subplot(1,2,2); plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)); plt.title('Grad-CAM'); plt.axis('off')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:24:22.283369Z","iopub.execute_input":"2025-09-25T17:24:22.283639Z","iopub.status.idle":"2025-09-25T17:24:23.748088Z","shell.execute_reply.started":"2025-09-25T17:24:22.283619Z","shell.execute_reply":"2025-09-25T17:24:23.747297Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Hiperparametre Optimizasyonu\n\nDeney yapılan parametreler:\n- Katman & filtre sayısı: 32→64→128 gibi artışlar\n- Kernel boyutları: 3x3 standardı, bazı yerlerde 5x5 denemesi\n- Dropout: 0.2 - 0.5 aralığı\n- Learning rate: 1e-3 → 1e-5 arası denemeler\n- Batch size: 16, 32, 64\n- Optimizer: Adam, SGD+momentum\n\nOtomatik arama için Keras Tuner veya RandomSearch önerilir.\n","metadata":{}},{"cell_type":"markdown","source":"## 9. Sonuçlar ve Değerlendirme\n\n- Model: Baseline CNN (ve/veya EfficientNetB0 transfer learning).\n- En iyi validation accuracy: **(buraya deneysel sonuçlarınızı yazın)**.\n- Confusion matrix ve classification report yukarıda gösterildi.\n- Grad-CAM görselleştirmeleri, modelin görüntüdeki tümör bölgelerine odaklandığını doğruladı / doğrulamadı (bunu gözle kontrol ederek yorumlayın).\n\n**Gelecek çalışmalar:**\n- Daha güçlü transfer learning (EfficientNet / ResNet50) ve fine-tuning\n- Class imbalance varsa class-weight veya oversampling uygulama\n- Segmentation (U-Net) ile lokasyon tespiti ve ardından classification\n","metadata":{}}]}